{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b0d6bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:22.729670Z",
     "iopub.status.busy": "2025-08-02T13:12:22.729406Z",
     "iopub.status.idle": "2025-08-02T13:12:26.830376Z",
     "shell.execute_reply": "2025-08-02T13:12:26.829759Z"
    },
    "papermill": {
     "duration": 4.108246,
     "end_time": "2025-08-02T13:12:26.831730",
     "exception": false,
     "start_time": "2025-08-02T13:12:22.723484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from typing import Optional, Tuple\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0296c923",
   "metadata": {
    "papermill": {
     "duration": 0.003454,
     "end_time": "2025-08-02T13:12:26.839342",
     "exception": false,
     "start_time": "2025-08-02T13:12:26.835888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e4bc89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:26.847687Z",
     "iopub.status.busy": "2025-08-02T13:12:26.847331Z",
     "iopub.status.idle": "2025-08-02T13:12:26.903495Z",
     "shell.execute_reply": "2025-08-02T13:12:26.902848Z"
    },
    "papermill": {
     "duration": 0.061748,
     "end_time": "2025-08-02T13:12:26.904592",
     "exception": false,
     "start_time": "2025-08-02T13:12:26.842844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class CFG:\n",
    "    epochs = 50\n",
    "    train_batch_size = 10\n",
    "    val_batch_size = 10\n",
    "    test_batch_size = 10\n",
    "    \n",
    "    train_start = 0\n",
    "    train_end = 4500\n",
    "    \n",
    "    val_start = 4500\n",
    "    val_end =  5000\n",
    "    \n",
    "    test_start = 5000\n",
    "    test_end = 5109\n",
    "    \n",
    "    lr = 2e-5\n",
    "    # a higer learning rate was used for CNN compared to timm models as these models do not use any pretrained weights or any form of transfer learning\n",
    "    # but for ViT even smaller learning rates did not yeild good results\n",
    "    patience = 5\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a41800a",
   "metadata": {
    "papermill": {
     "duration": 0.003305,
     "end_time": "2025-08-02T13:12:26.911882",
     "exception": false,
     "start_time": "2025-08-02T13:12:26.908577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a929d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:26.919607Z",
     "iopub.status.busy": "2025-08-02T13:12:26.919358Z",
     "iopub.status.idle": "2025-08-02T13:12:26.924397Z",
     "shell.execute_reply": "2025-08-02T13:12:26.923835Z"
    },
    "papermill": {
     "duration": 0.010241,
     "end_time": "2025-08-02T13:12:26.925536",
     "exception": false,
     "start_time": "2025-08-02T13:12:26.915295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class PathologyDataset(Dataset):\n",
    "    def __init__(self, patches, labels, start_idx, end_idx):\n",
    "        self.patches = patches\n",
    "        self.labels = labels\n",
    "        self.start_idx = start_idx\n",
    "        self.end_idx = end_idx\n",
    "        self.length = end_idx - start_idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = self.start_idx + idx\n",
    "        \n",
    "        patch = self.patches[actual_idx].astype(np.float32) \n",
    "        label = self.labels[actual_idx]\n",
    "        \n",
    "        patch = torch.tensor(patch) \n",
    "        label = torch.tensor(label, dtype=torch.long) \n",
    "        \n",
    "        return patch, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd91315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:26.933105Z",
     "iopub.status.busy": "2025-08-02T13:12:26.932883Z",
     "iopub.status.idle": "2025-08-02T13:12:26.969619Z",
     "shell.execute_reply": "2025-08-02T13:12:26.968636Z"
    },
    "papermill": {
     "duration": 0.041837,
     "end_time": "2025-08-02T13:12:26.970803",
     "exception": false,
     "start_time": "2025-08-02T13:12:26.928966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (5109, 3, 256, 256)\n",
      "Labels shape: (5109,)\n",
      "Labels range: 0 to 7\n",
      "Unique labels: [0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.load(\"/kaggle/input/miccaireg/images.npy\", mmap_mode=\"r\")\n",
    "labels = np.load(\"/kaggle/input/miccaireg/labels.npy\")\n",
    "\n",
    "print(f\"Inputs shape: {inputs.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Labels range: {labels.min()} to {labels.max()}\")\n",
    "print(f\"Unique labels: {np.unique(labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be1f2682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:26.979089Z",
     "iopub.status.busy": "2025-08-02T13:12:26.978859Z",
     "iopub.status.idle": "2025-08-02T13:12:27.534868Z",
     "shell.execute_reply": "2025-08-02T13:12:27.534010Z"
    },
    "papermill": {
     "duration": 0.561552,
     "end_time": "2025-08-02T13:12:27.536179",
     "exception": false,
     "start_time": "2025-08-02T13:12:26.974627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 450\n",
      "Val batches: 50\n",
      "Test batches: 11\n",
      "Sample batch shape: torch.Size([10, 3, 256, 256])\n",
      "Sample labels shape: torch.Size([10])\n",
      "Sample labels: tensor([5, 5, 0, 6, 0, 6, 3, 6, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = PathologyDataset(inputs, labels, CFG.train_start, CFG.train_end)\n",
    "val_dataset = PathologyDataset(inputs, labels, CFG.val_start, CFG.val_end)\n",
    "test_dataset = PathologyDataset(inputs, labels, CFG.test_start, CFG.test_end)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG.train_batch_size, shuffle=True, pin_memory=True,num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=CFG.val_batch_size, shuffle=False, pin_memory=True,num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=CFG.test_batch_size, shuffle=False, pin_memory=True,num_workers=2)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "sample_batch, sample_labels = next(iter(train_loader))\n",
    "print(f\"Sample batch shape: {sample_batch.shape}\")\n",
    "print(f\"Sample labels shape: {sample_labels.shape}\")\n",
    "print(f\"Sample labels: {sample_labels}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e2530f",
   "metadata": {
    "papermill": {
     "duration": 0.004375,
     "end_time": "2025-08-02T13:12:27.544529",
     "exception": false,
     "start_time": "2025-08-02T13:12:27.540154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c432c",
   "metadata": {
    "papermill": {
     "duration": 0.003421,
     "end_time": "2025-08-02T13:12:27.551499",
     "exception": false,
     "start_time": "2025-08-02T13:12:27.548078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ViT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9257108f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:27.560418Z",
     "iopub.status.busy": "2025-08-02T13:12:27.560167Z",
     "iopub.status.idle": "2025-08-02T13:12:27.585231Z",
     "shell.execute_reply": "2025-08-02T13:12:27.584468Z"
    },
    "papermill": {
     "duration": 0.031342,
     "end_time": "2025-08-02T13:12:27.586373",
     "exception": false,
     "start_time": "2025-08-02T13:12:27.555031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Convert image patches to embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size: int = 256, patch_size: int = 16, in_channels: int = 3, embed_dim: int = 768):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_patches = (img_size // patch_size) ** 2\n",
    "        \n",
    "        # convolution to create patches and embed them\n",
    "        self.projection = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch_size, channels, height, width)\n",
    "        x = self.projection(x)  # (batch_size, embed_dim, n_patches_sqrt, n_patches_sqrt)\n",
    "        x = x.flatten(2)        # (batch_size, embed_dim, n_patches)\n",
    "        x = x.transpose(1, 2)   # (batch_size, n_patches, embed_dim)\n",
    "        return x\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int = 768, num_heads: int = 12, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "        self.qkv = nn.Linear(embed_dim, embed_dim * 3, bias=False)\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, seq_len, embed_dim = x.shape\n",
    "        \n",
    "        qkv = self.qkv(x).reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)  # (3, batch_size, num_heads, seq_len, head_dim)\n",
    "        q, k, v = qkv.unbind(0)\n",
    "        \n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        x = (attn @ v).transpose(1, 2).reshape(batch_size, seq_len, embed_dim)\n",
    "        x = self.proj(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, embed_dim: int = 768, mlp_ratio: float = 4.0, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(embed_dim * mlp_ratio)\n",
    "        \n",
    "        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim: int = 768, num_heads: int = 12, mlp_ratio: float = 4.0, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = MultiHeadAttention(embed_dim, num_heads, dropout)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = MLP(embed_dim, mlp_ratio, dropout)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class PathologyViT(nn.Module):\n",
    "    \"\"\"\n",
    "        img_size: Input image size (default: 256)\n",
    "        patch_size: Patch size (default: 16)\n",
    "        in_channels: Number of input channels (default: 3)\n",
    "        num_classes: Number of classification classes (default: 8)\n",
    "        embed_dim: Embedding dimension (default: 768)\n",
    "        depth: Number of transformer layers (default: 12)\n",
    "        num_heads: Number of attention heads (default: 12)\n",
    "        mlp_ratio: MLP hidden dim ratio (default: 4.0)\n",
    "        dropout: Dropout rate (default: 0.1)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size: int = 256,\n",
    "        patch_size: int = 16,\n",
    "        in_channels: int = 3,\n",
    "        num_classes: int = 8,\n",
    "        embed_dim: int = 768,\n",
    "        depth: int = 12,\n",
    "        num_heads: int = 12,\n",
    "        mlp_ratio: float = 4.0,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.embed_dim = embed_dim\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        # Patch embedding\n",
    "        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n",
    "        n_patches = self.patch_embed.n_patches\n",
    "        \n",
    "        # CLS token and position embeddings\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, n_patches + 1, embed_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Transformer blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        \n",
    "        # Classification head\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "    \n",
    "    def forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the transformer, returns CLS token features\n",
    "        This is useful for feature extraction in Stage 2\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        x = self.patch_embed(x)  # (batch_size, n_patches, embed_dim)\n",
    "        \n",
    "        # Add CLS token\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        x = torch.cat([cls_tokens, x], dim=1)  # (batch_size, n_patches + 1, embed_dim)\n",
    "        \n",
    "        # Add position embeddings\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Pass through transformer blocks\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # Final layer norm\n",
    "        x = self.norm(x)\n",
    "        return x[:, 0]  # Return CLS token features: (batch_size, embed_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for classification\n",
    "        \"\"\"\n",
    "        # Get CLS token features\n",
    "        cls_features = self.forward_features(x)  # (batch_size, embed_dim)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.head(cls_features)  # (batch_size, num_classes)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def get_attention_maps(self, x: torch.Tensor, layer_idx: int = -1) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Extract attention maps for visualization\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Forward pass up to the specified layer\n",
    "        x = self.patch_embed(x)\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        x = torch.cat([cls_tokens, x], dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if i == layer_idx or (layer_idx == -1 and i == len(self.blocks) - 1):\n",
    "                # Extract attention from this layer\n",
    "                x_norm = block.norm1(x)\n",
    "                qkv = block.attn.qkv(x_norm).reshape(batch_size, x.shape[1], 3, block.attn.num_heads, block.attn.head_dim)\n",
    "                qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "                q, k, v = qkv.unbind(0)\n",
    "                \n",
    "                attn = (q @ k.transpose(-2, -1)) * block.attn.scale\n",
    "                attn = F.softmax(attn, dim=-1)\n",
    "                \n",
    "                # Return attention maps (focusing on CLS token attention to patches)\n",
    "                return attn[:, :, 0, 1:]  # (batch_size, num_heads, n_patches)\n",
    "            \n",
    "            x = block(x)\n",
    "        \n",
    "        return None\n",
    "\n",
    "def vit_model(model_size: str = \"base\", num_classes: int = 8, img_size: int = 256) -> PathologyViT:\n",
    "    configs = {\n",
    "        \"tiny\": {\"embed_dim\": 192, \"depth\": 12, \"num_heads\": 3},\n",
    "        \"small\": {\"embed_dim\": 384, \"depth\": 12, \"num_heads\": 6},\n",
    "        \"base\": {\"embed_dim\": 768, \"depth\": 12, \"num_heads\": 12},\n",
    "        \"large\": {\"embed_dim\": 1024, \"depth\": 24, \"num_heads\": 16}\n",
    "    }\n",
    "    \n",
    "    if model_size not in configs:\n",
    "        raise ValueError(f\"Model size {model_size} not supported. Choose from {list(configs.keys())}\")\n",
    "    \n",
    "    config = configs[model_size]\n",
    "    \n",
    "    return PathologyViT(\n",
    "        img_size=img_size,\n",
    "        patch_size=16,\n",
    "        in_channels=3,\n",
    "        num_classes=num_classes,\n",
    "        embed_dim=config[\"embed_dim\"],\n",
    "        depth=config[\"depth\"],\n",
    "        num_heads=config[\"num_heads\"],\n",
    "        mlp_ratio=4.0,\n",
    "        dropout=0.1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369cd32",
   "metadata": {
    "papermill": {
     "duration": 0.003462,
     "end_time": "2025-08-02T13:12:27.593574",
     "exception": false,
     "start_time": "2025-08-02T13:12:27.590112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d3a32a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:27.601945Z",
     "iopub.status.busy": "2025-08-02T13:12:27.601710Z",
     "iopub.status.idle": "2025-08-02T13:12:27.629741Z",
     "shell.execute_reply": "2025-08-02T13:12:27.628997Z"
    },
    "papermill": {
     "duration": 0.033899,
     "end_time": "2025-08-02T13:12:27.631057",
     "exception": false,
     "start_time": "2025-08-02T13:12:27.597158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Basic convolutional block with BatchNorm and ReLU\"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int = 3, \n",
    "                 stride: int = 1, padding: int = 1, use_dropout: bool = False, dropout_rate: float = 0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.use_dropout = use_dropout\n",
    "        if use_dropout:\n",
    "            self.dropout = nn.Dropout2d(dropout_rate)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with skip connection\"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1, downsample: bool = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if downsample or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class PathologyConvNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 8,\n",
    "        in_channels: int = 3,\n",
    "        base_channels: int = 64,\n",
    "        use_se: bool = True,\n",
    "        use_residual: bool = True,\n",
    "        dropout_rate: float = 0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.use_se = use_se\n",
    "        self.use_residual = use_residual\n",
    "        \n",
    "        # Initial convolution - larger kernel to capture more context\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_channels, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.layer1 = self._make_layer(base_channels, base_channels, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(base_channels, base_channels * 2, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(base_channels * 2, base_channels * 4, 3, stride=2)\n",
    "        self.layer4 = self._make_layer(base_channels * 4, base_channels * 8, 3, stride=2)\n",
    "        self.layer5 = self._make_layer(base_channels * 8, base_channels * 8, 2, stride=2)\n",
    "        \n",
    "        # Global pooling and classification\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Feature dimension for downstream tasks\n",
    "        self.feature_dim = base_channels * 8\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim, self.feature_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(self.feature_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _make_layer(self, in_channels: int, out_channels: int, num_blocks: int, stride: int = 1):\n",
    "        layers = []\n",
    "        \n",
    "        # First block (may have stride > 1 for downsampling)\n",
    "        if self.use_residual:\n",
    "            layers.append(ResidualBlock(in_channels, out_channels, stride, stride > 1))\n",
    "            in_channels = out_channels\n",
    "            \n",
    "            # Remaining blocks\n",
    "            for _ in range(1, num_blocks):\n",
    "                layers.append(ResidualBlock(in_channels, out_channels))\n",
    "        else:\n",
    "            # Simple conv blocks\n",
    "            layers.append(ConvBlock(in_channels, out_channels, stride=stride, use_dropout=True))\n",
    "            in_channels = out_channels\n",
    "            \n",
    "            for _ in range(1, num_blocks):\n",
    "                layers.append(ConvBlock(in_channels, out_channels, use_dropout=True))\n",
    "        \n",
    "        # Add SE block if requested\n",
    "        if self.use_se:\n",
    "            layers.append(SEBlock(out_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights using He initialization for ReLU networks\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns: (batch_size, feature_dim) tensor\n",
    "        \"\"\"\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        \n",
    "        x = self.global_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for classification\n",
    "        \"\"\"\n",
    "        features = self.forward_features(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "    def get_feature_maps(self, x: torch.Tensor, layer_name: str = 'layer4') -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Extract intermediate feature maps for visualization\n",
    "        \"\"\"\n",
    "        x = self.stem(x)\n",
    "        if layer_name == 'stem':\n",
    "            return x\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        if layer_name == 'layer1':\n",
    "            return x\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        if layer_name == 'layer2':\n",
    "            return x\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        if layer_name == 'layer3':\n",
    "            return x\n",
    "        \n",
    "        x = self.layer4(x)\n",
    "        if layer_name == 'layer4':\n",
    "            return x\n",
    "        \n",
    "        x = self.layer5(x)\n",
    "        if layer_name == 'layer5':\n",
    "            return x\n",
    "        \n",
    "        return x\n",
    "\n",
    "class LightweightConvNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 8,\n",
    "        in_channels: int = 3,\n",
    "        base_channels: int = 32,\n",
    "        dropout_rate: float = 0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            ConvBlock(in_channels, base_channels, kernel_size=3, stride=1),\n",
    "            ConvBlock(base_channels, base_channels, kernel_size=3, stride=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 2  \n",
    "            ConvBlock(base_channels, base_channels * 2, kernel_size=3, stride=1),\n",
    "            ConvBlock(base_channels * 2, base_channels * 2, kernel_size=3, stride=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 3\n",
    "            ConvBlock(base_channels * 2, base_channels * 4, kernel_size=3, stride=1),\n",
    "            ConvBlock(base_channels * 4, base_channels * 4, kernel_size=3, stride=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 4\n",
    "            ConvBlock(base_channels * 4, base_channels * 8, kernel_size=3, stride=1),\n",
    "            ConvBlock(base_channels * 8, base_channels * 8, kernel_size=3, stride=1),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        \n",
    "        self.feature_dim = base_channels * 8\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(self.feature_dim, self.feature_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(self.feature_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.forward_features(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "def cnn_model(model_size: str = \"standard\",num_classes: int = 8,**kwargs) -> nn.Module:\n",
    "    \n",
    "    if model_size == \"small\":\n",
    "        return LightweightConvNet(num_classes=num_classes, **kwargs)\n",
    "    \n",
    "    elif model_size == \"base\":\n",
    "        return PathologyConvNet(\n",
    "            num_classes=num_classes,\n",
    "            base_channels=64,\n",
    "            use_se=False,\n",
    "            use_residual=True,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    elif model_size == \"large\":\n",
    "        return PathologyConvNet(\n",
    "            num_classes=num_classes,\n",
    "            base_channels=64,\n",
    "            use_se=True,\n",
    "            use_residual=True,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"model_size must be one of: small, base, large\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e10d0e0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:27.639345Z",
     "iopub.status.busy": "2025-08-02T13:12:27.639115Z",
     "iopub.status.idle": "2025-08-02T13:12:28.066142Z",
     "shell.execute_reply": "2025-08-02T13:12:28.065302Z"
    },
    "papermill": {
     "duration": 0.432643,
     "end_time": "2025-08-02T13:12:28.067423",
     "exception": false,
     "start_time": "2025-08-02T13:12:27.634780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully!\n",
      "Total parameters: 21,677,960\n",
      "Trainable parameters: 21,677,960\n",
      "Model size: 21.68M parameters\n"
     ]
    }
   ],
   "source": [
    "model_type = \"vit\"\n",
    "variant = \"small\"\n",
    "\n",
    "model = vit_model(\"small\", num_classes=8, img_size=256)\n",
    "# model = cnn_model(\"small\", num_classes=8)\n",
    "\n",
    "model = model.to(CFG.device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model created successfully!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: {total_params/1e6:.2f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eecb099a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:28.076494Z",
     "iopub.status.busy": "2025-08-02T13:12:28.075981Z",
     "iopub.status.idle": "2025-08-02T13:12:28.690297Z",
     "shell.execute_reply": "2025-08-02T13:12:28.689599Z"
    },
    "papermill": {
     "duration": 0.620025,
     "end_time": "2025-08-02T13:12:28.691507",
     "exception": false,
     "start_time": "2025-08-02T13:12:28.071482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward_features(torch.rand(2,3,256,256).to(CFG.device)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcab71bf",
   "metadata": {
    "papermill": {
     "duration": 0.003617,
     "end_time": "2025-08-02T13:12:28.699091",
     "exception": false,
     "start_time": "2025-08-02T13:12:28.695474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690c8d1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:28.707871Z",
     "iopub.status.busy": "2025-08-02T13:12:28.707193Z",
     "iopub.status.idle": "2025-08-02T13:12:33.072526Z",
     "shell.execute_reply": "2025-08-02T13:12:33.071589Z"
    },
    "papermill": {
     "duration": 4.370962,
     "end_time": "2025-08-02T13:12:33.073807",
     "exception": false,
     "start_time": "2025-08-02T13:12:28.702845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 2e-05\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x79736a583910>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG.lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    min_lr=1e-7,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"Criterion: {criterion}\")\n",
    "print(f\"Optimizer: {optimizer}\")\n",
    "print(f\"Scheduler: {scheduler}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f63302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:33.083484Z",
     "iopub.status.busy": "2025-08-02T13:12:33.082690Z",
     "iopub.status.idle": "2025-08-02T13:12:33.087892Z",
     "shell.execute_reply": "2025-08-02T13:12:33.087380Z"
    },
    "papermill": {
     "duration": 0.010744,
     "end_time": "2025-08-02T13:12:33.088938",
     "exception": false,
     "start_time": "2025-08-02T13:12:33.078194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def manage_checkpoints(save_dir, keep_last_n=3):\n",
    "    checkpoint_pattern = os.path.join(save_dir, 'epoch*.pth')\n",
    "    checkpoint_files = glob.glob(checkpoint_pattern)\n",
    "    \n",
    "    checkpoints = []\n",
    "    for checkpoint_file in checkpoint_files:\n",
    "        filename = os.path.basename(checkpoint_file)\n",
    "        try:\n",
    "            epoch_num = int(filename.replace('epoch', '').replace('.pth', ''))\n",
    "            checkpoints.append((epoch_num, checkpoint_file))\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    checkpoints.sort(reverse=True)\n",
    "    \n",
    "    if len(checkpoints) > keep_last_n:\n",
    "        for _, checkpoint_file in checkpoints[keep_last_n:]:\n",
    "            try:\n",
    "                os.remove(checkpoint_file)\n",
    "                print(f\"Removed old checkpoint: {os.path.basename(checkpoint_file)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error removing checkpoint {checkpoint_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac3f371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:12:33.097894Z",
     "iopub.status.busy": "2025-08-02T13:12:33.097499Z",
     "iopub.status.idle": "2025-08-02T13:18:54.923264Z",
     "shell.execute_reply": "2025-08-02T13:18:54.922308Z"
    },
    "papermill": {
     "duration": 381.831689,
     "end_time": "2025-08-02T13:18:54.924608",
     "exception": false,
     "start_time": "2025-08-02T13:12:33.092919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "============================================================\n",
      "Epoch 1/50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 450/450 [00:40<00:00, 11.00it/s, Loss=2.0358]\n",
      "Validation Epoch 1: 100%|██████████| 50/50 [00:01<00:00, 28.18it/s, Loss=2.0143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0322\n",
      "Val Loss: 2.0173\n",
      "Val Accuracy: 0.00%\n",
      "\n",
      "============================================================\n",
      "Epoch 2/50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 450/450 [00:40<00:00, 11.04it/s, Loss=1.8265]\n",
      "Validation Epoch 2: 100%|██████████| 50/50 [00:01<00:00, 30.17it/s, Loss=1.0714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8405\n",
      "Val Loss: 1.8333\n",
      "Val Accuracy: 10.40%\n",
      "\n",
      "============================================================\n",
      "Epoch 3/50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 450/450 [00:40<00:00, 11.11it/s, Loss=1.6857]\n",
      "Validation Epoch 3: 100%|██████████| 50/50 [00:01<00:00, 30.60it/s, Loss=1.8662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5905\n",
      "Val Loss: 1.7619\n",
      "Val Accuracy: 35.80%\n",
      "\n",
      "============================================================\n",
      "Epoch 4/50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 450/450 [00:40<00:00, 11.11it/s, Loss=1.2196]\n",
      "Validation Epoch 4: 100%|██████████| 50/50 [00:01<00:00, 30.74it/s, Loss=0.8510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4334\n",
      "Val Loss: 1.1537\n",
      "Val Accuracy: 59.40%\n",
      "\n",
      "============================================================\n",
      "Epoch 5/50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 450/450 [00:40<00:00, 11.11it/s, Loss=1.1550]\n",
      "Validation Epoch 5: 100%|██████████| 50/50 [00:01<00:00, 30.11it/s, Loss=6.1617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2848\n",
      "Val Loss: 3.6530\n",
      "Val Accuracy: 37.60%\n",
      "Patience: 1/5\n",
      "\n",
      "============================================================\n",
      "Epoch 6/50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 450/450 [00:40<00:00, 11.11it/s, Loss=1.3563]\n",
      "Validation Epoch 6: 100%|██████████| 50/50 [00:01<00:00, 30.22it/s, Loss=1.7635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1703\n",
      "Val Loss: 1.6563\n",
      "Val Accuracy: 44.80%\n",
      "Patience: 2/5\n",
      "\n",
      "============================================================\n",
      "Epoch 7/50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 450/450 [00:40<00:00, 11.11it/s, Loss=0.7987]\n",
      "Validation Epoch 7: 100%|██████████| 50/50 [00:01<00:00, 30.26it/s, Loss=6.2305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0895\n",
      "Val Loss: 3.5392\n",
      "Val Accuracy: 38.20%\n",
      "Patience: 3/5\n",
      "\n",
      "============================================================\n",
      "Epoch 8/50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 450/450 [00:40<00:00, 11.11it/s, Loss=1.4518]\n",
      "Validation Epoch 8: 100%|██████████| 50/50 [00:01<00:00, 30.23it/s, Loss=3.1261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0634\n",
      "Val Loss: 2.1780\n",
      "Val Accuracy: 44.20%\n",
      "LR decreased to 1e-05\n",
      "Patience: 4/5\n",
      "\n",
      "============================================================\n",
      "Epoch 9/50\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 450/450 [00:40<00:00, 11.10it/s, Loss=0.5318]\n",
      "Validation Epoch 9: 100%|██████████| 50/50 [00:01<00:00, 30.53it/s, Loss=1.0551]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9974\n",
      "Val Loss: 1.3029\n",
      "Val Accuracy: 47.20%\n",
      "Patience: 5/5\n",
      "Early stopping triggered after 9 epochs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "save_dir = \"/kaggle/working\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "all_step_train_losses = []\n",
    "all_epoch_train_losses = []\n",
    "all_epoch_val_losses = []\n",
    "\n",
    "for epoch in range(CFG.epochs):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch+1}/{CFG.epochs}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    train_pbar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
    "    for batch_idx, (data, target) in enumerate(train_pbar):\n",
    "        data, target = data.to(CFG.device), target.to(CFG.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        step_loss = loss.item()\n",
    "        train_losses.append(step_loss)\n",
    "        all_step_train_losses.append(step_loss)  \n",
    "        train_pbar.set_postfix({'Loss': f'{step_loss:.4f}'})\n",
    "    \n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "    all_epoch_train_losses.append(avg_train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\")\n",
    "        for data, target in val_pbar:\n",
    "            data, target = data.to(CFG.device), target.to(CFG.device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            val_pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    all_epoch_val_losses.append(avg_val_loss)\n",
    "    \n",
    "    val_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Val Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    prev_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(avg_val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if prev_lr != new_lr:\n",
    "        print(f\"LR decreased to {new_lr}\")\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "\n",
    "        model_filename = f\"epoch{epoch+1}.pth\"\n",
    "        model_path = os.path.join(save_dir, model_filename)\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict() if scheduler is not None else None,\n",
    "            'loss': float(avg_train_loss),\n",
    "            'val_loss': float(avg_val_loss),\n",
    "            'val_accuracy': float(val_accuracy),\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, model_path)\n",
    "        manage_checkpoints(save_dir, keep_last_n=5)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"Patience: {patience_counter}/{CFG.patience}\")\n",
    "        \n",
    "        if patience_counter >= CFG.patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8839e2",
   "metadata": {
    "papermill": {
     "duration": 0.268351,
     "end_time": "2025-08-02T13:18:55.462030",
     "exception": false,
     "start_time": "2025-08-02T13:18:55.193679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TESTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5faeee70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:18:56.074650Z",
     "iopub.status.busy": "2025-08-02T13:18:56.074353Z",
     "iopub.status.idle": "2025-08-02T13:18:56.975457Z",
     "shell.execute_reply": "2025-08-02T13:18:56.974424Z"
    },
    "papermill": {
     "duration": 1.167617,
     "end_time": "2025-08-02T13:18:56.977036",
     "exception": false,
     "start_time": "2025-08-02T13:18:55.809419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 1\n",
      "TESTING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 11/11 [00:00<00:00, 18.62it/s, Loss=1.9146]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "Test Loss: 1.9359\n",
      "Test Accuracy: 5.50%\n",
      "\n",
      "Per-class Accuracy:\n",
      "Class 0: No samples\n",
      "Class 1: 0.00% (0/1)\n",
      "Class 2: 0.00% (0/13)\n",
      "Class 3: 0.00% (0/60)\n",
      "Class 4: No samples\n",
      "Class 5: 100.00% (6/6)\n",
      "Class 6: 0.00% (0/29)\n",
      "Class 7: No samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_path = os.path.join(save_dir, \"epoch1.pth\")\n",
    "if os.path.exists(best_model_path):\n",
    "    checkpoint = torch.load(best_model_path )\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded model from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "print(\"TESTING\")\n",
    "\n",
    "model.eval()\n",
    "test_losses = []\n",
    "correct = 0\n",
    "total = 0\n",
    "class_correct = list(0. for i in range(8))\n",
    "class_total   = list(0. for i in range(8))\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_pbar = tqdm(test_loader, desc=\"Testing\")\n",
    "    for data, target in test_pbar:\n",
    "        data, target = data.to(CFG.device), target.to(CFG.device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_losses.append(loss.item())\n",
    "        \n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        c = (predicted == target)\n",
    "        \n",
    "        if c.dim() == 0:  \n",
    "            c = c.unsqueeze(0)\n",
    "            \n",
    "        for i in range(target.size(0)):\n",
    "            label = target[i].item() \n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "        \n",
    "        test_pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "avg_test_loss = np.mean(test_losses)\n",
    "test_accuracy = 100 * correct / total\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"\\nPer-class Accuracy:\")\n",
    "for i in range(8):\n",
    "    if class_total[i] > 0:\n",
    "        accuracy = 100 * class_correct[i] / class_total[i]\n",
    "        print(f\"Class {i}: {accuracy:.2f}% ({int(class_correct[i])}/{int(class_total[i])})\")\n",
    "    else:\n",
    "        print(f\"Class {i}: No samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00529ded",
   "metadata": {
    "papermill": {
     "duration": 0.325986,
     "end_time": "2025-08-02T13:18:57.566321",
     "exception": false,
     "start_time": "2025-08-02T13:18:57.240335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FINAL CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f03d11e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:18:58.103344Z",
     "iopub.status.busy": "2025-08-02T13:18:58.103060Z",
     "iopub.status.idle": "2025-08-02T13:18:58.263597Z",
     "shell.execute_reply": "2025-08-02T13:18:58.262997Z"
    },
    "papermill": {
     "duration": 0.428602,
     "end_time": "2025-08-02T13:18:58.264998",
     "exception": false,
     "start_time": "2025-08-02T13:18:57.836396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_model_path = os.path.join(save_dir, \"finalcheckpoint.pth\")\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'num_classes': 8,\n",
    "    'img_size': 256,\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'test_loss': float(avg_test_loss),\n",
    "}, final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29889bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T13:18:58.855917Z",
     "iopub.status.busy": "2025-08-02T13:18:58.855641Z",
     "iopub.status.idle": "2025-08-02T13:18:58.861591Z",
     "shell.execute_reply": "2025-08-02T13:18:58.861059Z"
    },
    "papermill": {
     "duration": 0.330367,
     "end_time": "2025-08-02T13:18:58.862611",
     "exception": false,
     "start_time": "2025-08-02T13:18:58.532244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    np.save(os.path.join(save_dir,  f\"train_step_losses_{model_type}_{variant}_scratch.npy\"), np.array(all_step_train_losses))\n",
    "    np.save(os.path.join(save_dir, f\"train_epoch_losses_{model_type}_{variant}_scratch.npy\"), np.array(all_epoch_train_losses))\n",
    "    np.save(os.path.join(save_dir,   f\"val_epoch_losses_{model_type}_{variant}_scratch.npy\"), np.array(all_epoch_val_losses))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce7ce6",
   "metadata": {
    "papermill": {
     "duration": 0.264153,
     "end_time": "2025-08-02T13:18:59.387799",
     "exception": false,
     "start_time": "2025-08-02T13:18:59.123646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7866202,
     "sourceId": 12647806,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 403.475429,
   "end_time": "2025-08-02T13:19:02.110644",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-02T13:12:18.635215",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
